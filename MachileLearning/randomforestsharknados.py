# -*- coding: utf-8 -*-
"""RandomForestSharknados.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1STSyuC8ilRBZu6cQ8tWOIPdRlSxTmwKx
"""

!pip install scikit-learn pandas joblib

import pandas as pd
import numpy as np
from google.colab import files
import io

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Sharknado/dataset_enriquecido.csv',
                    sep=',', encoding='utf-8')

df.head()

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
import joblib

def treinar_modelo_tubaroes(df):
    """
    Função principal para treinar o modelo.
    Recebe o DataFrame carregado como argumento.
    """
    # --- 1. Preparar os Dados para o Treino ---
    print("2. A preparar os dados para o treino do modelo...")

    features = [
        'sst_c',
        'proximidade_colonia_km',
        'profundidade_m',
        'declive_graus',
        'clorofila_mg_m3',
        'energia_dinamica_score'
    ]

    df_treino = df[df['tipo_amostra'].str.contains('treino')]
    df_teste = df[df['tipo_amostra'].str.contains('teste')]

    X_treino = df_treino[features]
    y_treino = df_treino['target']

    X_teste = df_teste[features]
    y_teste = df_teste['target']

    print(f"   - {len(df_treino)} amostras para treino.")
    print(f"   - {len(df_teste)} amostras para teste.")

    # --- 2. Criar e Treinar o Pipeline de IA ---
    print("\n3. A construir e a treinar o pipeline de Machine Learning...")
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'))
    ])
    pipeline.fit(X_treino, y_treino)
    print("   - Treino concluído!")

    # --- 3. Avaliar a Performance do Modelo ---
    print("\n4. A avaliar a performance do modelo no conjunto de teste...")
    predicoes_classe = pipeline.predict(X_teste)
    probabilidades = pipeline.predict_proba(X_teste)[:, 1]

    precisao = accuracy_score(y_teste, predicoes_classe)
    print(f"   - Precisão (Accuracy): {precisao * 100:.2f}%")
    print("\n   - Relatório de Classificação:")
    print(classification_report(y_teste, predicoes_classe))

    # --- 4. Analisar a Importância dos Parâmetros ---
    print("\n5. Importância de cada parâmetro para o modelo:")
    importancia_features = pd.Series(pipeline.named_steps['classifier'].feature_importances_, index=features).sort_values(ascending=False)
    print(importancia_features)

    # --- 5. Salvar o Modelo no Ambiente do Colab ---
    print("\n6. A salvar o pipeline de IA treinado...")
    nome_ficheiro_pipeline = "modelo_tubarao_v1.pkl"
    joblib.dump(pipeline, nome_ficheiro_pipeline)
    print(f"   - Pipeline de IA salvo em: '{nome_ficheiro_pipeline}'")

    # --- 6. Exemplo Prático ---
    print("\n--- EXEMPLO DE USO DO MODELO ---")
    novo_local = pd.DataFrame([{'sst_c': 15.5, 'proximidade_colonia_km': 10.2, 'profundidade_m': 180.0, 'declive_graus': 30.5, 'clorofila_mg_m3': 2.1, 'energia_dinamica_score': 0.9}])
    probabilidade_avistamento = pipeline.predict_proba(novo_local)[:, 1][0]
    print("Para um novo local com as condições de exemplo:")
    print(f"\nA probabilidade de avistamento de um tubarão-branco é de: {probabilidade_avistamento * 100:.2f}%")

    # Retorna o nome do ficheiro do modelo para a próxima célula
    return nome_ficheiro_pipeline

# --- Ponto de Entrada ---
# Executa a função de treino se o DataFrame (df) foi carregado com sucesso
if df is not None:
    nome_ficheiro_modelo = treinar_modelo_tubaroes(df)
else:
    print("\nA execução foi interrompida porque o DataFrame de dados não foi carregado.")
    nome_ficheiro_modelo = None